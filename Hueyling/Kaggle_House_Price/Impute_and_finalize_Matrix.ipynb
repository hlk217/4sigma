{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of features that are correlated with the SalePrice.\n",
    "Treat the NA as a category on it's own. If the feature is still important, it should show up.\n",
    "\n",
    "\n",
    "Couple features we want to make sure.\n",
    "MSSubClass -- appears to be number but it's actually categorical.\n",
    "\n",
    "https://emredjan.github.io/blog/2017/07/11/emulating-r-plots-in-python/#leverageplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12 records within the test set are potentially problematics.\n",
    "- They are index 1556, 1916, 1946, 2121, 2152, 2189, 2217, 2251, 2474, 2490, 2577, 2905 in the final combined set.\n",
    "- They are Null in some fields which never existed in the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1556, 1916, 1946, 2121, 2152, 2189, 2217, 2251, 2474, 2490, 2577,\n",
       "            2905],\n",
       "           dtype='int64', name='Id')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "df_train = df_train.set_index(\"Id\")\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "df_test_price = pd.read_csv('data/sample_submission.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"') \n",
    "\n",
    "test_null_columns=df_test.columns[df_test.isnull().any()] \n",
    "train_null_columns=df_train.columns[df_train.isnull().any()] \n",
    "test_null_only_ColIdx = test_null_columns.difference(train_null_columns)\n",
    "\n",
    "test_null_only_RowIdx = [ df_test[df_test[idx].isnull()].index.tolist() for idx in test_null_only_ColIdx ]\n",
    "test_null_only_RowIdx = list ( set(x for l in test_null_only_RowIdx for x in l) )\n",
    "\n",
    "problematicTestSet = df_test.loc[ df_test.index.isin( test_null_only_RowIdx ) ]\n",
    "problematicTestPrice = df_test_price.loc[ df_test_price.index.isin( test_null_only_RowIdx ) ]  #12 records\n",
    "problematicTestPrice = problematicTestPrice.drop( columns=['Id'] )\n",
    "problematicTestSet = pd.concat([problematicTestSet, problematicTestPrice], axis=1, sort=True)\n",
    "\n",
    "fineTestSet = df_test.loc[ ~df_test.index.isin( test_null_only_RowIdx ) ]\n",
    "fineTestPrice = df_test_price.loc[ ~df_test_price.index.isin( test_null_only_RowIdx ) ]  #1447 records\n",
    "fineTestSet = pd.concat([fineTestSet, fineTestPrice], axis=1, sort=True)\n",
    "\n",
    "problematicTestSet= problematicTestSet.set_index(\"Id\")\n",
    "fineTestSet = fineTestSet.set_index(\"Id\")\n",
    "df_test = df_test.set_index(\"Id\")\n",
    "df_test_price = df_test_price.set_index(\"Id\")\n",
    "\n",
    "df_test = pd.concat([df_test, df_test_price], axis=1, sort=True)\n",
    "df = pd.concat([df_train,df_test], axis=0, sort=True)\n",
    "\n",
    "#null_columns=df.columns[df.isnull().any()] \n",
    "#missCases = df[null_columns].isnull().sum() \n",
    "#print( len(missCases) -1 )  # Number of features that will have NA value, -1 is b/c NA value for the testing data.\n",
    "#missCases.sort_values(ascending=False)\n",
    "\n",
    "#df.loc[2121]\n",
    "\n",
    "problematicTestSet.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to check out the records in the fields that we will merge and dummy them together. \n",
    "- Correct Exterior1st and Exterior2nd, Replace  :Brk Cmn  -> BrkComm and CmentBd  -> CemntBd\n",
    "- Check BsmtFinType1 and BsmtFinType2. Everything is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_WdShing', 'x_BrkComm', 'x_CemntBd'}\n",
      "{'x_Brk Cmn', 'x_CmentBd', 'x_Other', 'x_Wd Shng'}\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "def checkWeirdExtra (inputDF, field1, field2):\n",
    "    var2_dummy_columns = pd.get_dummies(inputDF[field1], prefix= \"x\")\n",
    "    #print( len( var2_dummy_columns.columns ) )\n",
    "\n",
    "    var1_dummy_columns = pd.get_dummies(inputDF[field2], prefix= \"x\")\n",
    "    #print( len( var1_dummy_columns.columns ) )\n",
    "\n",
    "    var_dummy_columns = pd.concat([var1_dummy_columns,var2_dummy_columns],join='outer', sort=True).groupby(level=0).sum()\n",
    "    #print( len( var_dummy_columns.columns ) )\n",
    "\n",
    "    print ( set( var_dummy_columns.columns) - set( var1_dummy_columns.columns ) )\n",
    "    print ( set( var_dummy_columns.columns) - set( var2_dummy_columns.columns ) )\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "checkWeirdExtra(df, \"Exterior1st\", \"Exterior2nd\")\n",
    "\n",
    "df.Exterior1st = df.Exterior1st.str.replace(\"Brk Cmn\", \"BrkComm\")\n",
    "df.Exterior2nd = df.Exterior2nd.str.replace(\"Brk Cmn\", \"BrkComm\")\n",
    "df.Exterior1st = df.Exterior1st.str.replace(\"CmentBd\", \"CemntBd\")\n",
    "df.Exterior2nd = df.Exterior2nd.str.replace(\"CmentBd\", \"CemntBd\")\n",
    "\n",
    "checkWeirdExtra(df, \"BsmtFinType1\", \"BsmtFinType2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start to purposely encode the information based on our best understanding.\n",
    "- Combine Exterior1st and Exterior2nd to **Exterior**\n",
    "- BsmtFinType1 and BsmtFinType2 to **Bsmt** \n",
    "    -Replace each type to it's actually square feet  BsmtFinSF1, BsmtFinSF2\n",
    "    -For Unf in type 1 and type2, replace it with the BsmtUnfSF\n",
    "- Combine BsmtFullBath, BsmtHalfBath to **BsmtBath**\n",
    "- Add all different PorchSF to **TotalProchSF**\n",
    "- Dummy MasVnrType to **MasVnr** and replace the value with MasVnrArea\n",
    "- Dummy PoolQC to **Pool** and replace the value with PoolArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purposelyEncodeData(inputDF):\n",
    "    \n",
    "    preProcessCatField = [\"PoolQC\",  \"MasVnrType\", \"Exterior1st\", \"Exterior2nd\", \"BsmtFinType1\", \"BsmtFinType2\"]\n",
    "    preProcessNumFiled = [ \"PoolArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"BsmtFullBath\", \"BsmtHalfBath\"]\n",
    "    \n",
    "    inputDF[preProcessCatField] = inputDF[preProcessCatField].fillna(\"Unknown\")\n",
    "    inputDF[preProcessNumFiled] = inputDF[preProcessNumFiled].fillna(-1)\n",
    "    \n",
    "    # Need to encode some fields based on their definition and drop the original.\n",
    "    # Exterior1st, Exterior2nd (Exterior covering on house)\n",
    "\n",
    "    var1_dummy_columns = pd.get_dummies(inputDF['Exterior1st'], prefix= \"Exterior\")\n",
    "    var2_dummy_columns = pd.get_dummies(inputDF['Exterior2nd'], prefix= \"Exterior\")\n",
    "    var_dummy_columns = pd.concat([var1_dummy_columns,var2_dummy_columns], join='outer', sort=True).groupby(level=0).sum()\n",
    "\n",
    "    for k, v in var1_dummy_columns.nunique().to_dict().items():\n",
    "        print('{}={}'.format(k,v))\n",
    "\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], join='outer', sort=True, axis=1)\n",
    "    inputDF = inputDF.drop( columns=['Exterior1st', 'Exterior2nd'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    # BsmtFinType1, BsmtFinType2, BsmtFinSF1 (Type 1 finished square feet), BsmtFinSF2 (Type 1 finished square feet), BsmtUnfSF: Unfinished square feet of basement area\n",
    "    # TotalBsmtSF: Total square feet of basement area keep\n",
    "    var1_dummy_columns = pd.get_dummies(inputDF['BsmtFinType1'], prefix= \"Bsmt\") \n",
    "    var1_dummy_columns = var1_dummy_columns.mul( inputDF['BsmtFinSF1'] , axis=0)\n",
    "    tmp = var1_dummy_columns['Bsmt_Unf']\n",
    "    tmp [ inputDF.loc[inputDF['BsmtFinType1'] == \"Unf\"].index ] = 1\n",
    "    tmp = tmp.mul( inputDF['BsmtUnfSF'] , axis=0)\n",
    "    var1_dummy_columns['Bsmt_Unf'] = tmp\n",
    "\n",
    "    var2_dummy_columns = pd.get_dummies(inputDF['BsmtFinType2'], prefix= \"Bsmt\") \n",
    "    var2_dummy_columns = var2_dummy_columns.mul( inputDF['BsmtFinSF2'] , axis=0)\n",
    "    tmp = var2_dummy_columns['Bsmt_Unf']\n",
    "    tmp [ inputDF.loc[inputDF['BsmtFinType2'] == \"Unf\"].index ] = 1\n",
    "    tmp = tmp.mul( inputDF['BsmtUnfSF'] , axis=0)\n",
    "    var2_dummy_columns['Bsmt_Unf'] = tmp\n",
    "\n",
    "    var_dummy_columns = pd.concat([var1_dummy_columns,var2_dummy_columns], join='outer', sort=True).groupby(level=0).sum()\n",
    "\n",
    "    for k, v in var_dummy_columns.nunique().to_dict().items():\n",
    "        print('{}={}'.format(k,v))\n",
    "\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], join='outer', sort=True, axis=1)\n",
    "    inputDF = inputDF.drop( columns=['BsmtFinType1', 'BsmtFinType1', 'BsmtFinType2', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    #BsmtFullBath, BsmtHalfBath  (number of type of bathroom in the basement)\n",
    "    inputDF['BsmtBath'] = inputDF[\"BsmtFullBath\"] + 0.5* inputDF[\"BsmtHalfBath\"] \n",
    "    inputDF = inputDF.drop( columns=['BsmtFullBath', 'BsmtHalfBath'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    #OpenPorchSF ( Open porch area in square feet)\n",
    "    #EnclosedPorch (Enclosed porch area in square feet)\n",
    "    #3SsnPorch (Three season porch area in square feet)\n",
    "    #ScreenPorch (Screen porch area in square feet)\n",
    "    inputDF[\"TotalProchSF\"] = inputDF[\"OpenPorchSF\"] + inputDF[\"EnclosedPorch\"] + inputDF[\"3SsnPorch\"] + inputDF[\"ScreenPorch\"] \n",
    "    print( inputDF.shape )\n",
    "\n",
    "    #MasVnrType, MasVnrArea\n",
    "    var_dummy_columns = pd.get_dummies(inputDF['MasVnrType'], prefix= \"MasVnr\") \n",
    "    var_dummy_columns = var_dummy_columns.mul( inputDF['MasVnrArea'] , axis=0)\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], join='outer', sort=True, axis=1)\n",
    "    inputDF = inputDF.drop( columns=['MasVnrType', 'MasVnrArea'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "\n",
    "    #PoolQC, PoolArea\n",
    "    var_dummy_columns = pd.get_dummies(inputDF['PoolQC'], prefix= \"Pool\") \n",
    "    var_dummy_columns = var_dummy_columns.mul( inputDF['PoolArea'] , axis=0)\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], axis=1)\n",
    "    inputDF = inputDF.drop( columns=['PoolQC', 'PoolArea'] )\n",
    "    print( inputDF.shape )\n",
    "    \n",
    "    return (inputDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exterior_AsbShng=2\n",
      "Exterior_AsphShn=2\n",
      "Exterior_BrkComm=2\n",
      "Exterior_BrkFace=2\n",
      "Exterior_CBlock=2\n",
      "Exterior_CemntBd=2\n",
      "Exterior_HdBoard=2\n",
      "Exterior_ImStucc=2\n",
      "Exterior_MetalSd=2\n",
      "Exterior_Plywood=2\n",
      "Exterior_Stone=2\n",
      "Exterior_Stucco=2\n",
      "Exterior_Unknown=2\n",
      "Exterior_VinylSd=2\n",
      "Exterior_Wd Sdng=2\n",
      "Exterior_WdShing=2\n",
      "(2919, 96)\n",
      "Bsmt_ALQ=370\n",
      "Bsmt_BLQ=283\n",
      "Bsmt_GLQ=619\n",
      "Bsmt_LwQ=199\n",
      "Bsmt_Rec=302\n",
      "Bsmt_Unf=1214\n",
      "Bsmt_Unknown=3\n",
      "(2919, 98)\n",
      "(2919, 97)\n",
      "(2919, 98)\n",
      "(2919, 101)\n",
      "(2919, 103)\n"
     ]
    }
   ],
   "source": [
    "new = purposelyEncodeData(df.copy())\n",
    "new.MSSubClass = new.MSSubClass.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([333, 2121], dtype='int64', name='Id')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[ new[\"Bsmt_Unknown\"] != 0 ].index\n",
    "## index = 333, BsmtFinType2 is unknown but it has square feet for type2\n",
    "## index = 2121 Nan for all the BsmtFinType series.\n",
    "## The cleaning should be techinically correct.\n",
    "# df [ df.index == 333 ].BsmtFinType2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the dummy result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 103)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1stFlrSF              int64\n",
       "2ndFlrSF              int64\n",
       "3SsnPorch             int64\n",
       "Alley                object\n",
       "BedroomAbvGr          int64\n",
       "BldgType             object\n",
       "BsmtCond             object\n",
       "BsmtExposure         object\n",
       "BsmtQual             object\n",
       "CentralAir           object\n",
       "Condition1           object\n",
       "Condition2           object\n",
       "Electrical           object\n",
       "EnclosedPorch         int64\n",
       "ExterCond            object\n",
       "ExterQual            object\n",
       "Fence                object\n",
       "FireplaceQu          object\n",
       "Fireplaces            int64\n",
       "Foundation           object\n",
       "FullBath              int64\n",
       "Functional           object\n",
       "GarageArea          float64\n",
       "GarageCars          float64\n",
       "GarageCond           object\n",
       "GarageFinish         object\n",
       "GarageQual           object\n",
       "GarageType           object\n",
       "GarageYrBlt         float64\n",
       "GrLivArea             int64\n",
       "                     ...   \n",
       "Exterior_HdBoard      uint8\n",
       "Exterior_ImStucc      uint8\n",
       "Exterior_MetalSd      uint8\n",
       "Exterior_Other      float64\n",
       "Exterior_Plywood      uint8\n",
       "Exterior_Stone        uint8\n",
       "Exterior_Stucco       uint8\n",
       "Exterior_Unknown      uint8\n",
       "Exterior_VinylSd      uint8\n",
       "Exterior_Wd Sdng      uint8\n",
       "Exterior_Wd Shng    float64\n",
       "Exterior_WdShing    float64\n",
       "Bsmt_ALQ            float64\n",
       "Bsmt_BLQ            float64\n",
       "Bsmt_GLQ            float64\n",
       "Bsmt_LwQ            float64\n",
       "Bsmt_Rec            float64\n",
       "Bsmt_Unf            float64\n",
       "Bsmt_Unknown        float64\n",
       "BsmtBath            float64\n",
       "TotalProchSF          int64\n",
       "MasVnr_BrkCmn       float64\n",
       "MasVnr_BrkFace      float64\n",
       "MasVnr_None         float64\n",
       "MasVnr_Stone        float64\n",
       "MasVnr_Unknown      float64\n",
       "Pool_Ex               int64\n",
       "Pool_Fa               int64\n",
       "Pool_Gd               int64\n",
       "Pool_Unknown          int64\n",
       "Length: 103, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( new.shape )\n",
    "new.dtypes\n",
    "#cols_to_transform = [\"MSSubClass\", \"MSZoning\"]\n",
    "#df_with_dummies = pd.get_dummies( df, columns = cols_to_transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new\n",
    "df_test = df[df.index >= min(df_test.index)]  ## determine if it is a test set or not. Have to encode all of them together.\n",
    "df_train = df[df.index < min(df_test.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the processed object to the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(\"df_train.pkl\")\n",
    "df_test.to_pickle(\"df_test.pkl\")\n",
    "df.to_pickle(\"df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
