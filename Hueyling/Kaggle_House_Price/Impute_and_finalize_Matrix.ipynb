{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of features that are correlated with the SalePrice.\n",
    "Treat the NA as a category on it's own. If the feature is still important, it should show up.\n",
    "\n",
    "\n",
    "Couple features we want to make sure.\n",
    "MSSubClass -- appears to be number but it's actually categorical.\n",
    "\n",
    "https://emredjan.github.io/blog/2017/07/11/emulating-r-plots-in-python/#leverageplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12 records within the test set are potentially problematics.\n",
    "- They are index 1556, 1916, 1946, 2121, 2152, 2189, 2217, 2251, 2474, 2490, 2577, 2905 in the final combined set.\n",
    "- They are Null in some fields which never existed in the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1556, 1916, 1946, 2121, 2152, 2189, 2217, 2251, 2474, 2490, 2577,\n",
       "            2905],\n",
       "           dtype='int64', name='Id')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "df_train_label = df_train[[\"Id\", \"SalePrice\"]]\n",
    "df_train = df_train.drop('SalePrice', axis=1)\n",
    "\n",
    "df_train = df_train.set_index(\"Id\")\n",
    "df_train_label = df_train_label.set_index(\"Id\")\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "\n",
    "test_null_columns=df_test.columns[df_test.isnull().any()] \n",
    "train_null_columns=df_train.columns[df_train.isnull().any()] \n",
    "test_null_only_ColIdx = test_null_columns.difference(train_null_columns)\n",
    "\n",
    "test_null_only_RowIdx = [ df_test[df_test[idx].isnull()].index.tolist() for idx in test_null_only_ColIdx ]\n",
    "test_null_only_RowIdx = list ( set(x for l in test_null_only_RowIdx for x in l) )\n",
    "\n",
    "problematicTestSet = df_test.loc[ df_test.index.isin( test_null_only_RowIdx ) ]\n",
    "\n",
    "fineTestSet = df_test.loc[ ~df_test.index.isin( test_null_only_RowIdx ) ]  #1447 records\n",
    "\n",
    "problematicTestSet= problematicTestSet.set_index(\"Id\")\n",
    "fineTestSet = fineTestSet.set_index(\"Id\")\n",
    "df_test = df_test.set_index(\"Id\")\n",
    "\n",
    "df = pd.concat([df_train,df_test], axis=0, sort=True)\n",
    "\n",
    "problematicTestSet.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to check out the records in the fields that we will merge and dummy them together. \n",
    "- Correct Exterior1st and Exterior2nd, Replace  :Brk Cmn  -> BrkComm and CmentBd  -> CemntBd\n",
    "- Check BsmtFinType1 and BsmtFinType2. Everything is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_BrkComm', 'x_WdShing', 'x_CemntBd'}\n",
      "{'x_Other', 'x_Wd Shng', 'x_CmentBd', 'x_Brk Cmn'}\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "def checkWeirdExtra (inputDF, field1, field2):\n",
    "    var2_dummy_columns = pd.get_dummies(inputDF[field1], prefix= \"x\")\n",
    "    #print( len( var2_dummy_columns.columns ) )\n",
    "\n",
    "    var1_dummy_columns = pd.get_dummies(inputDF[field2], prefix= \"x\")\n",
    "    #print( len( var1_dummy_columns.columns ) )\n",
    "\n",
    "    var_dummy_columns = pd.concat([var1_dummy_columns,var2_dummy_columns],join='outer', sort=True).groupby(level=0).sum()\n",
    "    #print( len( var_dummy_columns.columns ) )\n",
    "\n",
    "    print ( set( var_dummy_columns.columns) - set( var1_dummy_columns.columns ) )\n",
    "    print ( set( var_dummy_columns.columns) - set( var2_dummy_columns.columns ) )\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "checkWeirdExtra(df, \"Exterior1st\", \"Exterior2nd\")\n",
    "\n",
    "df.Exterior1st = df.Exterior1st.str.replace(\"Brk Cmn\", \"BrkComm\")\n",
    "df.Exterior2nd = df.Exterior2nd.str.replace(\"Brk Cmn\", \"BrkComm\")\n",
    "df.Exterior1st = df.Exterior1st.str.replace(\"CmentBd\", \"CemntBd\")\n",
    "df.Exterior2nd = df.Exterior2nd.str.replace(\"CmentBd\", \"CemntBd\")\n",
    "df.Exterior1st = df.Exterior1st.str.replace(\"Wd Shng\", \"WdShing\")\n",
    "df.Exterior2nd = df.Exterior2nd.str.replace(\"Wd Shng\", \"WdShing\")\n",
    "\n",
    "checkWeirdExtra(df, \"BsmtFinType1\", \"BsmtFinType2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start to purposely encode the information based on our best understanding.\n",
    "- Combine Exterior1st and Exterior2nd to **Exterior**\n",
    "- BsmtFinType1 and BsmtFinType2 to **Bsmt** \n",
    "    -Replace each type to it's actually square feet  BsmtFinSF1, BsmtFinSF2\n",
    "    -For Unf in type 1 and type2, replace it with the BsmtUnfSF\n",
    "- Combine BsmtFullBath, BsmtHalfBath to **BsmtBath**\n",
    "- Add all different PorchSF to **TotalProchSF**\n",
    "- Dummy MasVnrType to **MasVnr** and replace the value with MasVnrArea\n",
    "- Dummy PoolQC to **Pool** and replace the value with PoolArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purposelyEncodeData(inputDF):\n",
    "    \n",
    "    preProcessCatField = [\"MasVnrType\", \"Exterior1st\", \"Exterior2nd\", \"BsmtFinType1\", \"BsmtFinType2\"]\n",
    "    preProcessNumFiled = [\"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\", \"BsmtFullBath\", \"BsmtHalfBath\"]\n",
    "    \n",
    "    inputDF[preProcessCatField] = inputDF[preProcessCatField].fillna(\"Unknown\")\n",
    "    inputDF[preProcessNumFiled] = inputDF[preProcessNumFiled].fillna(-1)\n",
    "    \n",
    "    # Need to encode some fields based on their definition and drop the original.\n",
    "    # Exterior1st, Exterior2nd (Exterior covering on house)\n",
    "\n",
    "    var1_dummy_columns = pd.get_dummies(inputDF['Exterior1st'], prefix= \"Exterior\")\n",
    "    var2_dummy_columns = pd.get_dummies(inputDF['Exterior2nd'], prefix= \"Exterior\")\n",
    "    var_dummy_columns = pd.concat([var1_dummy_columns,var2_dummy_columns], join='outer', sort=True).groupby(level=0).sum()\n",
    "    var_dummy_columns = var_dummy_columns.replace(2, 1) \n",
    "    \n",
    "    #for k, v in var1_dummy_columns.nunique().to_dict().items():\n",
    "    #    print('{}={}'.format(k,v))\n",
    "\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], join='outer', sort=True, axis=1)\n",
    "    inputDF = inputDF.drop( columns=['Exterior1st', 'Exterior2nd'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    # BsmtFinType1, BsmtFinType2, BsmtFinSF1 (Type 1 finished square feet), BsmtFinSF2 (Type 1 finished square feet), BsmtUnfSF: Unfinished square feet of basement area\n",
    "    # TotalBsmtSF: Total square feet of basement area keep\n",
    "    var1_dummy_columns = pd.get_dummies(inputDF['BsmtFinType1'], prefix= \"Bsmt\") \n",
    "    var1_dummy_columns = var1_dummy_columns.mul( inputDF['BsmtFinSF1'] , axis=0)\n",
    "    tmp = var1_dummy_columns['Bsmt_Unf']\n",
    "    tmp [ inputDF.loc[inputDF['BsmtFinType1'] == \"Unf\"].index ] = 1\n",
    "    tmp = tmp.mul( inputDF['BsmtUnfSF'] , axis=0)\n",
    "    var1_dummy_columns['Bsmt_Unf'] = tmp\n",
    "\n",
    "    var2_dummy_columns = pd.get_dummies(inputDF['BsmtFinType2'], prefix= \"Bsmt\") \n",
    "    var2_dummy_columns = var2_dummy_columns.mul( inputDF['BsmtFinSF2'] , axis=0)\n",
    "    tmp = var2_dummy_columns['Bsmt_Unf']\n",
    "    tmp [ inputDF.loc[inputDF['BsmtFinType2'] == \"Unf\"].index ] = 1\n",
    "    tmp = tmp.mul( inputDF['BsmtUnfSF'] , axis=0)\n",
    "    var2_dummy_columns['Bsmt_Unf'] = tmp\n",
    "    \n",
    "    for i, v in var1_dummy_columns['Bsmt_Unf'].items():\n",
    "        if v > 0:\n",
    "            var2_dummy_columns['Bsmt_Unf'].loc[i] = 0\n",
    "\n",
    "    var_dummy_columns = pd.concat([var1_dummy_columns,var2_dummy_columns], join='outer', sort=True).groupby(level=0).sum()\n",
    "\n",
    "    #for k, v in var_dummy_columns.nunique().to_dict().items():\n",
    "    #    print('{}={}'.format(k,v))\n",
    "\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], join='outer', sort=True, axis=1)\n",
    "    inputDF = inputDF.drop( columns=['BsmtFinType1', 'BsmtFinType1', 'BsmtFinType2', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    #BsmtFullBath, BsmtHalfBath  (number of type of bathroom in the basement)\n",
    "    inputDF['BsmtBath'] = inputDF[\"BsmtFullBath\"] + 0.5* inputDF[\"BsmtHalfBath\"] \n",
    "    inputDF = inputDF.drop( columns=['BsmtFullBath', 'BsmtHalfBath'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    #OpenPorchSF ( Open porch area in square feet)\n",
    "    #EnclosedPorch (Enclosed porch area in square feet)\n",
    "    #3SsnPorch (Three season porch area in square feet)\n",
    "    #ScreenPorch (Screen porch area in square feet)\n",
    "    inputDF[\"TotalProchSF\"] = inputDF[\"OpenPorchSF\"] + inputDF[\"EnclosedPorch\"] + inputDF[\"3SsnPorch\"] + inputDF[\"ScreenPorch\"] \n",
    "    print( inputDF.shape )\n",
    "\n",
    "    #MasVnrType, MasVnrArea\n",
    "    var_dummy_columns = pd.get_dummies(inputDF['MasVnrType'], prefix= \"MasVnr\") \n",
    "    var_dummy_columns = var_dummy_columns.mul( inputDF['MasVnrArea'] , axis=0)\n",
    "    inputDF = pd.concat([inputDF, var_dummy_columns], join='outer', sort=True, axis=1)\n",
    "    inputDF = inputDF.drop( columns=['MasVnrType', 'MasVnrArea'] )\n",
    "    print( inputDF.shape )\n",
    "\n",
    "    return (inputDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 94)\n",
      "(2919, 96)\n",
      "(2919, 95)\n",
      "(2919, 96)\n",
      "(2919, 99)\n"
     ]
    }
   ],
   "source": [
    "new = purposelyEncodeData(df.copy())\n",
    "new.MSSubClass = new.MSSubClass.astype('object')\n",
    "# new.OverallCond and new.OverallQual is already encoded. So, don't have to do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([333, 2121], dtype='int64', name='Id')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[ new[\"Bsmt_Unknown\"] != 0 ].index\n",
    "## index = 333, BsmtFinType2 is unknown but it has square feet for type2, we keep this as unknown b/c we don't know \n",
    "## index = 2121 Nan for all the BsmtFinType series.\n",
    "## The cleaning should be techinically correct.\n",
    "#df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the level of each categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley 2\n",
      "BldgType 5\n",
      "BsmtCond 4\n",
      "BsmtExposure 4\n",
      "BsmtQual 4\n",
      "CentralAir 2\n",
      "Condition1 9\n",
      "Condition2 8\n",
      "Electrical 5\n",
      "ExterCond 5\n",
      "ExterQual 4\n",
      "Fence 4\n",
      "FireplaceQu 5\n",
      "Foundation 6\n",
      "Functional 7\n",
      "GarageCond 5\n",
      "GarageFinish 3\n",
      "GarageQual 5\n",
      "GarageType 6\n",
      "Heating 6\n",
      "HeatingQC 5\n",
      "HouseStyle 8\n",
      "KitchenQual 4\n",
      "LandContour 4\n",
      "LandSlope 3\n",
      "LotConfig 5\n",
      "LotShape 4\n",
      "MSSubClass 16\n",
      "MSZoning 5\n",
      "MiscFeature 4\n",
      "Neighborhood 25\n",
      "PavedDrive 3\n",
      "PoolQC 3\n",
      "RoofMatl 8\n",
      "RoofStyle 6\n",
      "SaleCondition 6\n",
      "SaleType 9\n",
      "Street 2\n",
      "Utilities 2\n"
     ]
    }
   ],
   "source": [
    "for c in new.columns:\n",
    "    if new[c].dtype == 'object':\n",
    "        print(c, len(new[c].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal Features\n",
    "Label Count encoding is good in general, however, some of the features are ordinal in nature.\n",
    "For example, we usually consider Excellent > Good > Average/Typical > Fair > Poor\n",
    "We can construct a dictionary like the following and map it to those columns:\n",
    "\n",
    "{'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa':2, 'Po':1}\n",
    "You need a different dictionary for columns with different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_cols = ['ExterQual', 'ExterCond','BsmtCond','HeatingQC', 'KitchenQual', \n",
    "           'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "ord_dic = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa':2, 'Po':1}\n",
    "\n",
    "ord_df = new.copy()\n",
    "for col in ord_cols:\n",
    "    ord_df[col] = ord_df[col].map(lambda x: ord_dic.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ord_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Count encoding\n",
    "- Rank categorical variables by count in the **training** set and transform the test set\n",
    "- Iterate counter for each CV fold - fit on the **new training set** and transform on the **new test set**\n",
    "- Useful for both linear or non-linear algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelCountEncoder(object):\n",
    "    def __init__(self):\n",
    "        self.count_dict = {}\n",
    "        self.rev_count_dict = {}\n",
    "        \n",
    "    def fit(self, column):\n",
    "        # We want to rank the key by its value and use the rank as the new value\n",
    "        count = column.value_counts()\n",
    "        self.count_dict = dict( list( zip (count.index, reversed(range(len(count)+1 ) ) ) ) ) \n",
    "        self.rev_count_dict = dict( list( zip ( reversed(range(len(count)+1 ) ) , count.index ) ) ) \n",
    "            \n",
    "    def transform(self, column):\n",
    "        # If a category only appears in the test set, we will assign the value to zero.\n",
    "        missing = 0\n",
    "        return column.map(lambda x: self.count_dict.get(x, missing))\n",
    "              \n",
    "    def fit_transform(self, column):\n",
    "        self.fit(column)\n",
    "        return self.transform(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 99)\n"
     ]
    }
   ],
   "source": [
    "df_label_count = new.copy()\n",
    "encodedDic = {}\n",
    "\n",
    "for i, c in enumerate ( df_label_count.columns ):\n",
    "    if df_label_count[c].dtype == 'object':\n",
    "        lce = LabelCountEncoder()\n",
    "        df_label_count[c] = lce.fit_transform(df_label_count[c])\n",
    "        encodedDic[df_label_count.columns[i]] = lce.rev_count_dict\n",
    "        \n",
    "print( df_label_count.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1stFlrSF              int64\n",
       "2ndFlrSF              int64\n",
       "3SsnPorch             int64\n",
       "Alley                 int64\n",
       "BedroomAbvGr          int64\n",
       "BldgType              int64\n",
       "BsmtCond              int64\n",
       "BsmtExposure          int64\n",
       "BsmtQual              int64\n",
       "CentralAir            int64\n",
       "Condition1            int64\n",
       "Condition2            int64\n",
       "Electrical            int64\n",
       "EnclosedPorch         int64\n",
       "ExterCond             int64\n",
       "ExterQual             int64\n",
       "Fence                 int64\n",
       "FireplaceQu           int64\n",
       "Fireplaces            int64\n",
       "Foundation            int64\n",
       "FullBath              int64\n",
       "Functional            int64\n",
       "GarageArea          float64\n",
       "GarageCars          float64\n",
       "GarageCond            int64\n",
       "GarageFinish          int64\n",
       "GarageQual            int64\n",
       "GarageType            int64\n",
       "GarageYrBlt         float64\n",
       "GrLivArea             int64\n",
       "                     ...   \n",
       "Exterior_AsphShn      uint8\n",
       "Exterior_BrkComm      uint8\n",
       "Exterior_BrkFace      uint8\n",
       "Exterior_CBlock       uint8\n",
       "Exterior_CemntBd      uint8\n",
       "Exterior_HdBoard      uint8\n",
       "Exterior_ImStucc      uint8\n",
       "Exterior_MetalSd      uint8\n",
       "Exterior_Other      float64\n",
       "Exterior_Plywood      uint8\n",
       "Exterior_Stone        uint8\n",
       "Exterior_Stucco       uint8\n",
       "Exterior_Unknown      uint8\n",
       "Exterior_VinylSd      uint8\n",
       "Exterior_Wd Sdng      uint8\n",
       "Exterior_WdShing      uint8\n",
       "Bsmt_ALQ            float64\n",
       "Bsmt_BLQ            float64\n",
       "Bsmt_GLQ            float64\n",
       "Bsmt_LwQ            float64\n",
       "Bsmt_Rec            float64\n",
       "Bsmt_Unf            float64\n",
       "Bsmt_Unknown        float64\n",
       "BsmtBath            float64\n",
       "TotalProchSF          int64\n",
       "MasVnr_BrkCmn       float64\n",
       "MasVnr_BrkFace      float64\n",
       "MasVnr_None         float64\n",
       "MasVnr_Stone        float64\n",
       "MasVnr_Unknown      float64\n",
       "Length: 99, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = df_label_count\n",
    "new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new\n",
    "df_test = df[df.index >= min(df_test.index)]  ## determine if it is a test set or not. Have to encode all of them together.\n",
    "df_train = df[df.index < min(df_test.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the processed object to the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df_train.to_pickle(\"df_train.pkl\")\n",
    "df_train_label.to_pickle(\"df_train_label.pkl\")\n",
    "df_test.to_pickle(\"df_test.pkl\")\n",
    "df.to_pickle(\"df.pkl\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('dic.pkl', 'wb') as handle:\n",
    "    pickle.dump(encodedDic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('dic.pkl', 'rb') as handle:\n",
    "    savedEncodeDic = pickle.load(handle)\n",
    "\n",
    "print (encodedDic == savedEncodeDic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df_train.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mix'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = encodedDic['Electrical']\n",
    "x[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
