{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pltimport\n",
    "\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "combined=pd.concat([train,test])\n",
    "combined.shape #2919\n",
    "#combined.iloc[:1460:,:] #train\n",
    "#combined.iloc[1460:,:] #test\n",
    "\n",
    "combined=combined.reset_index()\n",
    "\n",
    "from preprocess import impute\n",
    "all_data, encodedDic = impute (combined, False)\n",
    "all_data_onehot, encodedDic = impute (combined, True) #one-hot\n",
    "\n",
    "train=all_data.iloc[:1460:,:] #train\n",
    "train_y=train[\"SalePrice\"]\n",
    "train_x=train[train.columns[train.columns!=\"SalePrice\"]]\n",
    "test=test.iloc[1460:,:]\n",
    "\n",
    "train_onehot=all_data_onehot.iloc[:1460:,:] #train\n",
    "train_y_onehot=train_onehot[\"SalePrice\"]\n",
    "train_x_onehot=train_onehot[train_onehot.columns[train_onehot.columns!=\"SalePrice\"]]\n",
    "test_onehot=train_onehot.iloc[1460:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot[forbx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "gs=gridspec.GridSpec(251,1)\n",
    "plt.figure(figsize=(16, 340))\n",
    "for i in range(train_onehot.shape[1]):\n",
    "    ax1 = plt.subplot(gs[i, 0])\n",
    "    ax1.set_title('')\n",
    "    ax1.set_ylabel(\"\")\n",
    "    ax1.set_xlabel(\"\")\n",
    "#     xlim=ax1.get_xlim()  \n",
    "    sns.distplot(train_onehot.iloc[:,i])\n",
    "    for tick in ax1.xaxis.get_major_ticks():\n",
    "        tick.label1On = False\n",
    "        tick.label2On = True\n",
    "#     for tick in ax1.yaxis.get_major_ticks():\n",
    "#         tick.label1On=True\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subset numerical variable that look skewed\n",
    "forbx=[\"1stFlrSF\",\"2ndFlrSF\",\"GarageArea\",\"GrLivArea\",\"LotArea\",\"LotFrontage\",\"SalePrice\",\"TotalBsmtSF\",\"TotalFlrSF\",\"Bsmt_Unf\",\"TotalProchSF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the skewness of the selected column\n",
    "from scipy.stats import skew\n",
    "skewed_data=all_data_onehot[forbx].apply(lambda x: skew(x))\n",
    "skewed = skewed_data[abs(skewed_data) > 0.75]\n",
    "skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "para=np.linspace(0.0005,0.00001, 50) #lambda tuning\n",
    "\n",
    "tunning_result=boxcox1p(skewed[5],para)\n",
    "xlen=len(tunning_result)\n",
    "df_= pd.DataFrame(tunning_result, index=range(xlen))\n",
    "\n",
    "\n",
    "# title = 'Ridge mse as a function of the regularization'\n",
    "axes = df_.plot()\n",
    "axes.set_xlabel('lambda')\n",
    "axes.set_ylabel('skewness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in skewed.index:\n",
    "    all_data_onehot[i]=boxcox1p(all_data_onehot[i],0.001)\n",
    "    print(train_onehot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_onehot[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_onehot.to_csv(\"bx_all_data_onehot.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data_=pd.read_csv(\"bx_all_data_onehot.csv\")\n",
    "\n",
    "\n",
    "bx_train_onehot=all_data_.iloc[:1460:,:] #train\n",
    "bx_train_y_onehot=bx_train_onehot[\"SalePrice\"]\n",
    "bx_train_x_onehot=bx_train_onehot[bx_train_onehot.columns[bx_train_onehot.columns!=\"SalePrice\"]]\n",
    "bx_test_onehot=bx_train_onehot.iloc[1460:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Comparison with BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With BX\n",
    "from sklearn.model_selection import GridSearchCV # search for the best lambda\n",
    "from sklearn import linear_model\n",
    "\n",
    "ridge = linear_model.Ridge(normalize=True) # create a ridge regression instance\n",
    "\n",
    "# find the best alpha (lambda) for ridge\n",
    "grid_param = [{'alpha': np.logspace(-4, 2, 100)}]\n",
    "para_search_ridge = GridSearchCV(estimator=ridge, param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "para_search_ridge.fit(bx_train_x_onehot, bx_train_y_onehot)\n",
    "\n",
    "print(para_search_ridge.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(para_search_ridge.best_score_)))\n",
    "\n",
    "# fit best ridge equation to all train data\n",
    "best_ridge_y = para_search_ridge.best_estimator_.predict(bx_train_x_onehot)\n",
    "print(\"RMSE: \", np.sqrt(np.mean((train_y_onehot-best_ridge_y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No BX\n",
    "from sklearn.model_selection import GridSearchCV # search for the best lambda\n",
    "from sklearn import linear_model\n",
    "\n",
    "ridge = linear_model.Ridge(normalize=True) # create a ridge regression instance\n",
    "\n",
    "# find the best alpha (lambda) for ridge\n",
    "grid_param = [{'alpha': np.logspace(-4, 2, 100)}]\n",
    "para_search_ridge = GridSearchCV(estimator=ridge, param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "para_search_ridge.fit(train_x_onehot, train_y_onehot)\n",
    "\n",
    "print(para_search_ridge.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(para_search_ridge.best_score_)))\n",
    "\n",
    "# fit best ridge equation to all train data\n",
    "best_ridge_y = para_search_ridge.best_estimator_.predict(train_x_onehot)\n",
    "print(\"RMSE: \", np.sqrt(np.mean((train_y_onehot-best_ridge_y)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression Comparion with BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NO BX\n",
    "from sklearn.model_selection import GridSearchCV # search for the best lambda\n",
    "from sklearn import linear_model\n",
    "\n",
    "lasso= linear_model.Lasso(normalize=True) # create a ridge regression instance\n",
    "\n",
    "# find the best alpha (lambda) for ridge\n",
    "grid_param = [{'alpha': np.logspace(-4.5, 2, 100)}]\n",
    "para_search_lasso = GridSearchCV(estimator=lasso, param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "para_search_lasso.fit(train_x_onehot, train_y_onehot)\n",
    "\n",
    "print(para_search_lasso.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(para_search_lasso.best_score_)))\n",
    "\n",
    "# fit best ridge equation to all train data\n",
    "best_lasso_y = para_search_lasso.best_estimator_.predict(train_x_onehot)\n",
    "print(\"RMSE: \", np.sqrt(np.mean((train_y_onehot-best_lasso_y)**2)))\n",
    "\n",
    "# {'alpha': 25.65020905680051}\n",
    "# Lowest RMSE found:  33809.958651596615\n",
    "# RMSE:  27539.866355369504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BX\n",
    "from sklearn.model_selection import GridSearchCV # search for the best lambda\n",
    "from sklearn import linear_model\n",
    "\n",
    "lasso= linear_model.Lasso(normalize=True) # create a ridge regression instance\n",
    "\n",
    "# find the best alpha (lambda) for ridge\n",
    "grid_param = [{'alpha': np.logspace(-4.5, 2, 100)}]\n",
    "para_search_lasso = GridSearchCV(estimator=lasso, param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "para_search_lasso.fit(bx_train_x_onehot, bx_train_y_onehot)\n",
    "\n",
    "print(para_search_lasso.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(para_search_lasso.best_score_)))\n",
    "\n",
    "# fit best ridge equation to all train data\n",
    "best_lasso_y = para_search_lasso.best_estimator_.predict(bx_train_x_onehot)\n",
    "print(\"RMSE: \", np.sqrt(np.mean((bx_train_y_onehot-best_lasso_y)**2)))\n",
    "\n",
    "# {'alpha': 25.65020905680051}\n",
    "# Lowest RMSE found:  32559.718946794015\n",
    "# RMSE:  28119.588145632715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Comparison with BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with BX\n",
    "from sklearn.model_selection import GridSearchCV # search for the best lambda\n",
    "from sklearn import linear_model\n",
    "\n",
    "EN= linear_model.ElasticNet(normalize=True) # create a ridge regression instance\n",
    "\n",
    "# find the best alpha (lambda) for ridge\n",
    "grid_param = [{'alpha': np.logspace(-4.5, 2, 50),'l1_ratio':np.linspace(0.1,0.9,20)}]\n",
    "para_search_EN = GridSearchCV(estimator=EN, param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "para_search_EN.fit(bx_train_x_onehot, bx_train_y_onehot)\n",
    "\n",
    "print(para_search_EN.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(para_search_EN.best_score_)))\n",
    "\n",
    "# fit best ridge equation to all train data\n",
    "best_EN_y = para_search_EN.best_estimator_.predict(bx_train_x_onehot)\n",
    "print(\"RMSE: \", np.sqrt(np.mean((bx_train_y_onehot-best_EN_y)**2)))\n",
    "\n",
    "# {'alpha': 0.0004941713361323838, 'l1_ratio': 0.3526315789473684}\n",
    "# Lowest RMSE found:  32670.8665945391\n",
    "# RMSE:  27932.17975891021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfunction import run_GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfunction import run_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_GB(bx_train_x_onehot,bx_train_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
