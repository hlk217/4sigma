{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data pre-processing: combine related fields based on their definition and drop the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['source'] = 'train'\n",
    "test['source'] = 'test'\n",
    "combine = pd.concat([train,test]).reset_index().drop('index', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat Exterior1st and Exterior2nd\n",
    "ext1 = pd.get_dummies(combine.Exterior1st) # df with dummify Exterior1st\n",
    "ext2 = pd.get_dummies(combine.Exterior2nd).rename(columns={'Brk Cmn':'BrkComm', 'CmentBd':'CemntBd', 'Wd Shng':'WdShing'}) # df with dummify Exterior2nd, correct typos in ext2\n",
    "ext = ext1.add(ext2, fill_value=0).astype('uint8').replace(2,1).add_prefix('ext_')  # combine dummified df and add a prefix \n",
    "combine = pd.concat([combine, ext], axis=1).drop(['Exterior1st', 'Exterior2nd'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine BsmtFullBath, BsmtHalfBath (number of type of bathroom in the basement)\n",
    "combine['bathtot'] = train.BsmtFullBath + train.BsmtHalfBath * 0.5\n",
    "combine = combine.drop(['BsmtFullBath', 'BsmtHalfBath'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat PoolQC, PoolArea\n",
    "poolinfo = pd.concat([combine.PoolArea,  pd.get_dummies(combine.PoolQC)], axis =1) # df with dummified PoolQC columns + pool area\n",
    "pool = poolinfo.apply(lambda row: row.replace(1, row['PoolArea']), axis=1) # cast pool area into dummified columns\n",
    "combine = pd.concat([combine, pool], axis =1).drop(['PoolArea', 'PoolQC'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat Bsmt \n",
    "# BsmtType1\n",
    "bsmt1info = pd.concat([combine.BsmtFinSF1, pd.get_dummies(combine.BsmtFinType1)], axis = 1) # df with dummified BsmtFinType1 columns + BsmtFinSF1\n",
    "bsmt1 = bsmt1info.apply(lambda row: row.replace(1, row['BsmtFinSF1']), axis = 1) # cast BsmtFinSF1 into dummified columns (unfinished SF will be handled in the BsmtFinType2 section since we are merging type1 and type2 at the end)\n",
    "\n",
    "# BsmtType2\n",
    "combine.BsmtFinSF2 = combine[['BsmtFinSF2','BsmtUnfSF']].apply(lambda row: row.replace(0, row['BsmtUnfSF']), axis = 1) # merge unfinished SF into BsmtFinSF2 column so all the unfinished SF + BsmtFinSF2 are in one column and can be cast onto the dummy columns\n",
    "bsmt2info = pd.concat([combine.BsmtFinSF2, pd.get_dummies(combine.BsmtFinType2)], axis = 1) # df with dummified BsmtFinType2 columns + BsmtFinSF2 (BsmtFinSF2 column here included both SF2 and unfinished SF)\n",
    "bsmt2 = bsmt2info.apply(lambda row: row.replace(1, row['BsmtFinSF2']), axis = 1) # cast BsmtFinSF2 into dummified columns\n",
    "\n",
    "bsmt = bsmt1.add(bsmt2, fill_value=0).drop(['BsmtFinSF1','BsmtFinSF2'], axis = 1).add_prefix('bsmt_') # combine dummified BsmtType1 and BsmtType2, drop original columns, add prefix \n",
    "combine = pd.concat([combine, bsmt], axis = 1).drop(['BsmtFinType1', 'BsmtFinType2', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat masonry \n",
    "#MasVnrType, MasVnrArea\n",
    "masonryinfo = pd.concat([combine.MasVnrArea, pd.get_dummies(combine.MasVnrType)], axis = 1) # df with dummified masonry columns + masonryArea\n",
    "masonry = masonryinfo.apply(lambda row: row.replace(1, row['MasVnrArea']), axis = 1) # cast masonryArea into dummified columns\n",
    "\n",
    "combine = pd.concat([combine, masonry], axis = 1).drop('MasVnrArea', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine different porch areas (OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch) and create a new col with total porch area\n",
    "combine['porchtot'] = sum([combine.OpenPorchSF, combine.EnclosedPorch, combine['3SsnPorch'], combine.ScreenPorch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine.to_csv('combine.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file to picked obj\n",
    "df_train.to_pickle(\"df_train.pkl\")\n",
    "df_test.to_pickle(\"df_test.pkl\")\n",
    "df.to_pickle(\"df.pkl\")\n",
    "\n",
    "\n",
    "# create na for dummy \n",
    "# factorized categorical col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
